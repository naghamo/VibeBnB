{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6fdc31d-841c-4933-a749-5826134b549a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install reverse_geocoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d9d168-83c0-46ae-b39e-8e75a26b7766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = Path().resolve().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from data.airbnb_data_loader import load_airbnb_data, load_raw_airbnb_data, select_relevant_columns, cast_and_clean_types, analyze_missing_values, analyze_distributions, parse_pricing_details, parse_category_ratings, apply_listing_feature_extraction\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, ArrayType\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "from config import continents\n",
    "from data.travel_cities_data_loader import load_travel_cities\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3212eae4-1a29-4880-b9a5-95ecfc11fac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Initial Airbnb Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b43afd5-e6bd-4719-89d7-1755d784f276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_airbnb = load_raw_airbnb_data(spark)\n",
    "sel_airbnb = select_relevant_columns(raw_airbnb)\n",
    "cast_airbnb = cast_and_clean_types(sel_airbnb)\n",
    "price_airbnb = parse_pricing_details(cast_airbnb)\n",
    "cat_airbnb = parse_category_ratings(price_airbnb)\n",
    "init_airbnb = apply_listing_feature_extraction(cat_airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e098b0f-68ec-46d8-b30d-70629a403e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_airbnb.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cd0cdc1-4de3-4725-ad45-c35ae536dd48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_airbnb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7c68dae-7cb1-47bc-a50d-bf34d9ea60ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(init_airbnb.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2150f78-ce78-45b7-b491-e4a4ed94cadf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_missing_values(init_airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b76e3a-dae0-421c-baa5-997eb3280d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_distributions(init_airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c83468-b159-40a0-8806-33324e123720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import DoubleType, IntegerType, FloatType, LongType\n",
    "\n",
    "def plot_numeric_distributions_fast(df, max_rows=10000, cols_per_row=3, show_kde=False):\n",
    "    \"\"\"\n",
    "    Optimized for speed: limits rows to max_rows and disables KDE by default.\n",
    "    \"\"\"\n",
    "    # 1. Identify Numeric Cols\n",
    "    numeric_cols = []\n",
    "    for field in df.schema.fields:\n",
    "        if isinstance(field.dataType, (DoubleType, IntegerType, FloatType, LongType)):\n",
    "            if \"id\" not in field.name.lower() and not field.name.startswith(\"is_\"):\n",
    "                numeric_cols.append(field.name)\n",
    "    \n",
    "    print(f\"Plotting {len(numeric_cols)} columns using max {max_rows} rows...\")\n",
    "\n",
    "    # 2. Optimized Sampling\n",
    "    # pdf = df.limit(max_rows).toPandas()\n",
    "\n",
    "    total = df.count()\n",
    "    fraction = min(1.0, max_rows / total)\n",
    "\n",
    "    pdf = (\n",
    "        df\n",
    "        .sample(withReplacement=False, fraction=fraction, seed=42)\n",
    "        .limit(max_rows)\n",
    "        .toPandas()\n",
    "    )\n",
    "\n",
    "    # 3. Setup Grid\n",
    "    n_cols = len(numeric_cols)\n",
    "    if n_cols == 0:\n",
    "        print(\"No numeric columns found.\")\n",
    "        return\n",
    "\n",
    "    n_rows = math.ceil(n_cols / cols_per_row)\n",
    "    \n",
    "    # HISTOGRAMS\n",
    "    fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(15, 3 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col_name in enumerate(numeric_cols):\n",
    "        # Drop NaNs just for this column\n",
    "        data = pdf[col_name].dropna()\n",
    "        \n",
    "        # KEY CHANGE: kde=show_kde (False by default) makes this 10x faster\n",
    "        # bins=30 ensures consistent granularity\n",
    "        sns.histplot(data, ax=axes[i], kde=show_kde, bins=30, color=\"#00A699\", edgecolor='none')\n",
    "        axes[i].set_title(col_name, fontsize=10)\n",
    "        axes[i].set_ylabel(\"\") # Save space\n",
    "        axes[i].set_xlabel(\"\")\n",
    "        \n",
    "    for i in range(n_cols, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Distributions ({max_rows} rows)\", y=1.02, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91fb97a1-8f22-4065-87cc-d2986580ccd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_numeric_distributions_fast(init_airbnb, max_rows=10000, show_kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fbd5eac-9717-40de-8468-03b4f400b34b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data.airbnb_data_loader import derive_price_per_night, normalize_currency_to_usd\n",
    "\n",
    "# Prepare the dataframe lazily\n",
    "df_prices = normalize_currency_to_usd(derive_price_per_night(init_airbnb))\n",
    "\n",
    "# Select, Sample (~10%), and Collect\n",
    "price_data = (\n",
    "    df_prices\n",
    "    .select(\"price_per_night\")\n",
    "    .dropna()\n",
    "    .sample(withReplacement=False, fraction=0.1, seed=42) \n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(price_data['price_per_night'], bins=100, color=\"#FF5A5F\", log_scale=True)\n",
    "plt.axvline(1300, color='black', linestyle='--', linewidth=2, label='Outlier Cap ($1300)')\n",
    "plt.title(f\"Distribution of Nightly Prices (Sampled {len(price_data):,} listings)\")\n",
    "plt.xlabel(\"Price (USD)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6587fbb-6baa-4412-85eb-58a91ce1457b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Initial OSM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72e008a8-2dd1-49cb-a3a0-b388a7c8b93b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_osm = spark.read.parquet(\"dbfs:/vibebnb/data/osm_pois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4cfe944-ea56-49fa-a1bf-50a312500dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_osm.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b74586f-5c26-4a99-b707-a95402824c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_osm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fbd1290-8be5-48bf-987e-27e8b9c7a0ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(init_osm.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b367d55e-18fa-45c1-aa87-53a49e6dcaae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_missing_values(init_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ddc6e2-58f6-4fbd-ad7a-1e76581f5959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_distributions(init_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11e4dc67-ba9e-4f2e-96be-13d9fa8d5025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_numeric_distributions_fast(init_osm, max_rows=10000, show_kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e98165bc-bcc1-4f1b-bbce-fbbfbe2414c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count by group\n",
    "init_osm_poi = init_osm.groupBy(\"poi_group\").count().toPandas().sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=init_osm_poi, x=\"count\", y=\"poi_group\", palette=\"viridis\")\n",
    "plt.xscale('log')\n",
    "plt.title(\"POI Counts by Category (Log Scale)\")\n",
    "plt.xlabel(\"Total Count (Log Scale)\")\n",
    "plt.ylabel(\"Category\")\n",
    "\n",
    "# # Add text annotation\n",
    "# top_cat = init_osm_poi.iloc[0]['poi_group']\n",
    "# top_val = init_osm_poi.iloc[0]['count']\n",
    "# bottom_cat = init_osm_poi.iloc[-1]['poi_group']\n",
    "# bottom_val = init_osm_poi.iloc[-1]['count']\n",
    "# plt.text(0.05, 0.5, \n",
    "#          f\"{top_cat} vs {bottom_cat} Ratio: {int(top_val/bottom_val)}:1\", \n",
    "#          fontsize=12, \n",
    "#          bbox=dict(facecolor='white', alpha=0.8),\n",
    "#          transform=plt.gca().transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc65c43-aef0-469d-a427-802ab9da5d51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Initial Travel City Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95565fee-8d9e-4ace-bd43-050ed63f274c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CITIES_PATH = \"dbfs:/vibebnb/data/travel_cities.parquet\"\n",
    "init_cities = spark.read.parquet(CITIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a1e05f-7620-4e8c-b433-da0b39d229ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_cities.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33f6704c-0b05-40f9-a0a3-3f79398376fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_cities.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8cf66b-3975-45b6-821a-f2934ae75deb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(init_cities.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc4ca32-aa38-4ea4-b983-58f5e612c852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_missing_values(init_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb4dc65-30c7-40e1-98d7-a329217ed0ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_distributions(init_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86947c53-bea5-4f6d-8a9f-ee1d4351a7ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_numeric_distributions_fast(init_cities, max_rows=10000, show_kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a851788-9da9-41b9-a444-67662962c147",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "pdf_cities = init_cities.toPandas()\n",
    "\n",
    "# Plot using the Pandas DataFrame\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(\n",
    "    data=pdf_cities, \n",
    "    x='budget_level', \n",
    "    order=['Budget', 'Mid-range', 'Luxury'], \n",
    "    palette=\"viridis\"\n",
    ")\n",
    "plt.title(\"Distribution of Economic Classifications\")\n",
    "plt.xlabel(\"Budget Level\")\n",
    "plt.ylabel(\"Number of Cities\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc9c11d1-7bf5-4265-a188-080684e73ee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bring data to Pandas first\n",
    "pdf_cities = init_cities.toPandas()\n",
    "\n",
    "# Define your helper function\n",
    "def extract_jan_jul(json_str):\n",
    "    try:\n",
    "        if not json_str: return pd.Series([None, None])\n",
    "        data = json.loads(json_str)\n",
    "        # Extract Avg for Month 1 (Jan) and Month 7 (Jul)\n",
    "        return pd.Series([data.get('1', {}).get('avg'), data.get('7', {}).get('avg')])\n",
    "    except:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# Apply the function on the PANDAS dataframe\n",
    "pdf_cities[['temp_jan', 'temp_jul']] = pdf_cities['avg_temp_monthly'].apply(extract_jan_jul)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=pdf_cities, x='temp_jan', y='temp_jul', hue='budget_level', palette='viridis', alpha=0.7)\n",
    "plt.plot([-10, 35], [-10, 35], 'r--', label=\"No Seasonality Line\") \n",
    "plt.title(\"Climate seasonality: Winter (Jan) vs Summer (Jul) Temperatures\")\n",
    "plt.xlabel(\"Average January Temp (°C)\")\n",
    "plt.ylabel(\"Average July Temp (°C)\")\n",
    "plt.legend(title=\"Budget\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcf43758-3a3c-4d5c-8230-5a67c5c85771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d04af1-698d-4262-98cd-968e2e9cbd6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cities_df = load_travel_cities(spark, CITIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69bff477-e807-462d-8513-e86f27795167",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airbnb_df = load_airbnb_data(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89e19a40-4e9c-4235-be41-018502106dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OSM_BASE_DIR = \"dbfs:/vibebnb/data/osm_pois\"\n",
    "OSM_PATHS = {\n",
    "    \"europe\": f\"{OSM_BASE_DIR}/europe_pois_enriched.parquet\",\n",
    "    \"asia\": f\"{OSM_BASE_DIR}/asia_pois_enriched.parquet\",\n",
    "    \"north_america\": f\"{OSM_BASE_DIR}/north_america_pois_enriched.parquet\",\n",
    "    \"south_america\": f\"{OSM_BASE_DIR}/south_america_pois_enriched.parquet\",\n",
    "    \"africa\": f\"{OSM_BASE_DIR}/africa_pois_enriched.parquet\",\n",
    "    \"antarctica\": f\"{OSM_BASE_DIR}/antarctica_pois_enriched.parquet\",\n",
    "    \"central_america\":f\"{OSM_BASE_DIR}/central_america_pois_enriched.parquet\",\n",
    "    \"australia\": f\"{OSM_BASE_DIR}/australia_oceania_pois_enriched.parquet\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def counts_from_cc(df, cc_col=\"addr_cc\"):\n",
    "    \"\"\"\n",
    "    Count rows per continent using continents dict.\n",
    "    Works for Airbnb + Cities (both have addr_cc).\n",
    "    \"\"\"\n",
    "    # map country code -> continent using a Spark \"when\" chain\n",
    "    cont_expr = None\n",
    "    for cont, cc_list in continents.items():\n",
    "        cond = F.col(cc_col).isin(cc_list)\n",
    "        cont_expr = F.when(cond, F.lit(cont)) if cont_expr is None else cont_expr.when(cond, F.lit(cont))\n",
    "    cont_expr = cont_expr.otherwise(F.lit(\"unknown\"))\n",
    "\n",
    "    out = (\n",
    "        df.select(F.col(cc_col).alias(\"addr_cc\"))\n",
    "          .where(F.col(\"addr_cc\").isNotNull())\n",
    "          .withColumn(\"continent\", cont_expr)\n",
    "          .groupBy(\"continent\")\n",
    "          .agg(F.count(\"*\").alias(\"n_rows\"))\n",
    "          .toPandas()\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def counts_from_osm_paths(osm_paths: dict, cc_col=\"addr_cc\"):\n",
    "    \"\"\"\n",
    "    Count rows per continent using the fact OSM is already split by continent file.\n",
    "    We still optionally filter to countries you care about in config.continents[continent].\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cont, path in osm_paths.items():\n",
    "        try:\n",
    "            df = spark.read.parquet(path).select(cc_col)\n",
    "   \n",
    "            if cont in continents:\n",
    "                df = df.where(F.col(cc_col).isin(continents[cont]))\n",
    "            n = df.count()\n",
    "            rows.append({\"continent\": cont, \"n_rows\": int(n)})\n",
    "        except Exception as e:\n",
    "            print(f\"[OSM] Skipping {cont} ({path}) -> {e}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "cities_df = load_travel_cities(spark, CITIES_PATH)\n",
    "\n",
    "# -------------------------\n",
    "# Compute counts\n",
    "# -------------------------\n",
    "airbnb_counts = counts_from_cc(airbnb_df, cc_col=\"addr_cc\")\n",
    "cities_counts = counts_from_cc(cities_df, cc_col=\"addr_cc\")\n",
    "osm_counts    = counts_from_osm_paths(OSM_PATHS, cc_col=\"addr_cc\")\n",
    "\n",
    "display(airbnb_counts)\n",
    "display(cities_counts)\n",
    "display(osm_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23070923-606a-47be-88da-e4bbe9b8eacd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install geopandas shapely pyproj fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe92ed44-0231-43f2-8004-bc276cedd33d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 1) Load world map + build continents geometry\n",
    "\n",
    "world = gpd.read_file(\n",
    "    \"https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip\"\n",
    ")\n",
    "\n",
    "world_cont = (\n",
    "    world[[\"CONTINENT\", \"geometry\"]]\n",
    "    .dissolve(by=\"CONTINENT\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Drop the irrelevant \"Seven seas\" polygon if present\n",
    "world_cont = world_cont[world_cont[\"CONTINENT\"] != \"Seven seas (open ocean)\"].copy()\n",
    "\n",
    "# Canonical continent mapping \n",
    "\n",
    "CONTINENT_MAP = {\n",
    "    \"africa\": \"africa\",\n",
    "    \"antarctica\": \"antarctica\",\n",
    "    \"asia\": \"asia\",\n",
    "    \"europe\": \"europe\",\n",
    "    \"north_america\": \"north_america\",\n",
    "    \"south_america\": \"south_america\",\n",
    "    \"oceania\": \"oceania\",\n",
    "    \"central_america\": \"north_america\",      \n",
    "    \"australia\": \"oceania\",\n",
    "    \"australia_oceania\": \"oceania\",\n",
    "    \"australia__oceania\": \"oceania\",\n",
    "}\n",
    "\n",
    "def _norm_raw(x):\n",
    "    \"\"\"Normalize raw strings to snake_case lowercase.\"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    return (\n",
    "        str(x)\n",
    "        .lower()\n",
    "        .strip()\n",
    "        .replace(\"-\", \"_\")\n",
    "        .replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "def to_canonical_continent(x):\n",
    "    \"\"\"\n",
    "    Map your dataset continent value to Natural Earth's continent bucket (snake_case).\n",
    "    Returns one of:\n",
    "      africa, antarctica, asia, europe, north_america, south_america, oceania\n",
    "    \"\"\"\n",
    "    k = _norm_raw(x)\n",
    "    return CONTINENT_MAP.get(k, k)  # fallback: keep normalized value (helps you spot unexpected names)\n",
    "\n",
    "# Normalize the map side too\n",
    "world_cont[\"continent_norm\"] = world_cont[\"CONTINENT\"].apply(_norm_raw).apply(to_canonical_continent)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Plot function (choropleth + labels)\n",
    "# -----------------------------\n",
    "def plot_continent_map(title, counts_df):\n",
    "    \"\"\"\n",
    "    counts_df expected columns:\n",
    "      - continent   (your continent naming)\n",
    "      - n_rows      (count)\n",
    "    \"\"\"\n",
    "    df = counts_df.copy()\n",
    "    df[\"continent_norm\"] = df[\"continent\"].apply(to_canonical_continent)\n",
    "\n",
    "    merged = world_cont.merge(\n",
    "        df[[\"continent_norm\", \"n_rows\"]],\n",
    "        on=\"continent_norm\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    merged[\"n_rows\"] = merged[\"n_rows\"].fillna(0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    merged.plot(\n",
    "        column=\"n_rows\",\n",
    "        ax=ax,\n",
    "        legend=True,\n",
    "        legend_kwds={\"label\": \"Rows\"}\n",
    "    )\n",
    "\n",
    "    # Add continent name labels near each polygon\n",
    "    reps = merged.geometry.representative_point()\n",
    "    for (name, x, y) in zip(merged[\"CONTINENT\"], reps.x, reps.y):\n",
    "        ax.text(\n",
    "            x, y, name,\n",
    "            fontsize=9,\n",
    "            ha=\"center\", va=\"center\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", pad=1.5)\n",
    "        )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_continent_map(\"Airbnb — rows per continent\", airbnb_counts)\n",
    "plot_continent_map(\"Travel Cities — rows per continent\", cities_counts)\n",
    "plot_continent_map(\"OSM — rows per continent\", osm_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5de71bd4-54e2-4ac1-8d64-4714baa02d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# WHAT\n",
    "%pip install \"scipy<1.11\" reverse_geocoder\n",
    "print(airbnb_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41524ba5-5e82-4124-9cd7-8d87216815e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_distributions(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f0ac5b-f50a-4bec-ae12-06205a1c1fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyze_distributions(airbnb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e483bbdc-4e6d-481a-b642-01a1a2baef5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20f29da5-27f5-4792-a6d4-19a34919bd9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter Datasets to Europe\n",
    "europe_cc = continents['europe']\n",
    "\n",
    "# Airbnb\n",
    "df_ab_eur = airbnb_df.filter(F.col(\"addr_cc\").isin(europe_cc))\n",
    "# Cities (Travel Hubs)\n",
    "df_ci_eur = cities_df.filter(F.col(\"addr_cc\").isin(europe_cc))\n",
    "# OSM (Already loaded from 'europe' file, but let's be safe)\n",
    "df_osm_eur = spark.read.parquet(OSM_PATHS[\"europe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a0712eb-3d0e-4d95-80b3-f0d522c15100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Countries that are physically complex (islands/transcontinental) and need explicit inclusion\n",
    "# GE=Georgia, TR=Turkey, SI=Slovenia, MT=Malta, IT=Italy (islands), SE=Sweden (Gotland), PT=Portugal (Azores/Madeira), ES=Spain (Canaries)\n",
    "EXTRA_COUNTRIES = [\"GE\", \"TR\", \"SI\", \"MT\", \"IT\", \"SE\", \"PT\", \"ES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a388ac50-fcb6-4445-99dc-28dea64fb34e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_ab = df_ab_eur.count()\n",
    "n_ci = df_ci_eur.count()\n",
    "n_osm = df_osm_eur.count()\n",
    "n_countries = df_ab_eur.select(\"addr_cc\").distinct().count()\n",
    "\n",
    "print(f\"--- FINAL EUROPEAN DATASET STATISTICS ---\")\n",
    "print(f\"Total Listings:   {n_ab:,}\")\n",
    "print(f\"Total POIs:       {n_osm:,}\")\n",
    "print(f\"Travel Cities:    {n_ci} (Major Tourist Hubs)\")\n",
    "print(f\"Countries:        {n_countries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93593ffb-454f-4437-a740-1118c25e8041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Aggregate Counts: Country x Category\n",
    "pdf_osm_composition = (\n",
    "    df_osm_eur\n",
    "    .groupBy(\"addr_cc\", \"poi_group\")\n",
    "    .count()\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "# 2. Filter to Top 10 Countries (to keep plot readable)\n",
    "top_countries = df_ab_eur.groupBy(\"addr_cc\").count().orderBy(F.desc(\"count\")).limit(10).toPandas()[\"addr_cc\"].tolist()\n",
    "pdf_plot = pdf_osm_composition[pdf_osm_composition[\"addr_cc\"].isin(top_countries)]\n",
    "\n",
    "# 3. Pivot: Rows=Country, Cols=Category, Values=Count\n",
    "pdf_pivot = pdf_plot.pivot(index=\"addr_cc\", columns=\"poi_group\", values=\"count\").fillna(0)\n",
    "\n",
    "# 4. Normalize to 100% (Calculate percentages)\n",
    "pdf_normalized = pdf_pivot.div(pdf_pivot.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# 5. Plot Stacked Bar Chart\n",
    "ax = pdf_normalized.plot(\n",
    "    kind=\"bar\", \n",
    "    stacked=True, \n",
    "    figsize=(12, 6), \n",
    "    colormap=\"tab20\", # High contrast palette\n",
    "    width=0.8\n",
    ")\n",
    "\n",
    "plt.title(\"Environmental 'Vibe' Composition by Country\")\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Percentage of National POIs\")\n",
    "plt.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79c7643c-00b0-414d-bf58-15cb4c421bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Create a \"Universe\" of all countries from your Config\n",
    "# This ensures we count countries that have ZERO cities (critical for sparsity)\n",
    "all_countries_data = []\n",
    "for cont, codes in continents.items():\n",
    "    for cc in codes:\n",
    "        all_countries_data.append({\"continent\": cont, \"addr_cc\": cc})\n",
    "\n",
    "pdf_all_countries = pd.DataFrame(all_countries_data)\n",
    "\n",
    "# 2. Get Actual City Counts per Country from Data\n",
    "# We use the enriched cities_df which has 'addr_cc'\n",
    "pdf_city_counts = (\n",
    "    cities_df\n",
    "    .groupBy(\"addr_cc\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"n_cities\")\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "# 3. Merge to calculate Sparsity\n",
    "# Left join ensures countries with 0 cities appear as NaN -> fill with 0\n",
    "pdf_sparsity = pd.merge(pdf_all_countries, pdf_city_counts, on=\"addr_cc\", how=\"left\")\n",
    "pdf_sparsity[\"n_cities\"] = pdf_sparsity[\"n_cities\"].fillna(0)\n",
    "\n",
    "# 4. Aggregation: Calculate Mean, Std, and Coverage\n",
    "sparsity_metrics = (\n",
    "    pdf_sparsity\n",
    "    .groupby(\"continent\")\n",
    "    .agg(\n",
    "        Total_Cities=('n_cities', 'sum'),\n",
    "        Total_Countries=('addr_cc', 'count'),\n",
    "        Avg_Cities_per_Country=('n_cities', 'mean'),\n",
    "        Std_Dev=('n_cities', 'std'),\n",
    "        Countries_with_Data=('n_cities', lambda x: (x > 0).sum())\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. Add \"Coverage %\" column\n",
    "sparsity_metrics[\"Coverage_Pct\"] = (\n",
    "    sparsity_metrics[\"Countries_with_Data\"] / sparsity_metrics[\"Total_Countries\"] * 100\n",
    ").round(1)\n",
    "\n",
    "# Format for display\n",
    "sparsity_metrics = sparsity_metrics.sort_values(\"Avg_Cities_per_Country\", ascending=False).round(2)\n",
    "\n",
    "# Display\n",
    "print(\"--- City Data Sparsity Analysis by Continent ---\")\n",
    "display(sparsity_metrics)\n",
    "\n",
    "# Optional: Quick textual summary for the report\n",
    "print(\"\\nQuick Report Summary:\")\n",
    "for ix, row in sparsity_metrics.iterrows():\n",
    "    print(f\"{ix}: {int(row['Total_Cities'])} cities across {int(row['Total_Countries'])} countries \"\n",
    "          f\"(Avg: {row['Avg_Cities_per_Country']} ± {row['Std_Dev']}). Coverage: {row['Coverage_Pct']}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9af6cf0-52eb-4fc2-985c-f881abfbac58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Aggregation for Plotting (Listings per Country)\n",
    "pdf_ab_counts = df_ab_eur.groupBy(\"addr_cc\").count() \\\n",
    "    .withColumnRenamed(\"count\", \"listings_count\") \\\n",
    "    .toPandas().sort_values(\"listings_count\", ascending=False).head(15)\n",
    "\n",
    "# Aggregation for Cities (Tourist Hubs per Country)\n",
    "pdf_ci_counts = df_ci_eur.groupBy(\"addr_cc\").count() \\\n",
    "    .withColumnRenamed(\"count\", \"cities_count\") \\\n",
    "    .toPandas()\n",
    "\n",
    "# Merge for side-by-side comparison\n",
    "pdf_merged = pd.merge(pdf_ab_counts, pdf_ci_counts, on=\"addr_cc\", how=\"left\")\n",
    "\n",
    "# --- PLOT OF EUROPEAN MARKET DISTRIBUTION ---\n",
    "# We use a dual-axis plot to show Listings (Bars) and City Hubs (Line/Points)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 1. Bar Plot (Listings)\n",
    "sns.barplot(\n",
    "    data=pdf_merged, \n",
    "    x=\"addr_cc\", \n",
    "    y=\"listings_count\", \n",
    "    color=\"#00A699\", \n",
    "    ax=ax1, \n",
    "    alpha=0.8\n",
    "    # No 'label=' here, avoiding auto-legend confusion\n",
    ")\n",
    "ax1.set_ylabel(\"Number of Listings\")\n",
    "ax1.set_xlabel(\"Country\")\n",
    "ax1.set_title(\"Top 15 European Markets: Listing Density vs. Tourist Hubs\")\n",
    "\n",
    "# 2. Scatter Plot (Cities)\n",
    "ax2 = ax1.twinx()\n",
    "sns.scatterplot(\n",
    "    data=pdf_merged, \n",
    "    x=\"addr_cc\", \n",
    "    y=\"cities_count\", \n",
    "    color=\"#FF5A5F\", \n",
    "    s=100, \n",
    "    ax=ax2, \n",
    "    marker=\"D\"\n",
    "    # No 'label=' here either\n",
    ")\n",
    "ax2.set_ylabel(\"Major Tourist Cities\")\n",
    "ax2.set_ylim(0, max(pdf_merged['cities_count']) * 1.2)\n",
    "\n",
    "# Manually define what the legend should look like\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#00A699', edgecolor='none', label='Airbnb Listings'),\n",
    "    Line2D([0], [0], marker='D', color='w', markerfacecolor='#FF5A5F', markersize=10, label='Major Tourist Cities')\n",
    "]\n",
    "\n",
    "# Place the legend on ax1\n",
    "ax1.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8defe51-579f-4b9c-9a6c-4758df3d5994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f916ea-478e-4325-92a1-db5b72f27434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from adjustText import adjust_text\n",
    "\n",
    "def count_by_country(df, cc_col=\"addr_cc\"):\n",
    "    return (\n",
    "        df.filter(F.col(cc_col).isNotNull())\n",
    "          .groupBy(cc_col)\n",
    "          .count()\n",
    "          .withColumnRenamed(\"count\", \"n_rows\")\n",
    "          .toPandas()\n",
    "    )\n",
    "\n",
    "pdf_airbnb_cc = count_by_country(df_ab_eur)\n",
    "pdf_cities_cc = count_by_country(df_ci_eur)\n",
    "pdf_osm_cc = count_by_country(df_osm_eur)\n",
    "\n",
    "\n",
    "def plot_europe_choropleth(title, counts_df, cc_col=\"addr_cc\"):\n",
    "    # Load Map (50m)\n",
    "    world = gpd.read_file(\"https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_countries.zip\")\n",
    "\n",
    "    # FIX MAP CODES: Patch '-99' codes so they match the group-by data (FR, NO, etc.)\n",
    "    world.loc[world['NAME'] == 'Norway', 'ISO_A2'] = 'NO'\n",
    "    world.loc[world['NAME'] == 'France', 'ISO_A2'] = 'FR'\n",
    "    world.loc[world['NAME'] == 'Kosovo', 'ISO_A2'] = 'XK'\n",
    "\n",
    "    # Filter Map\n",
    "    europe_map = world[\n",
    "        (world[\"CONTINENT\"] == \"Europe\") | \n",
    "        (world[\"ISO_A2\"].isin(EXTRA_COUNTRIES))\n",
    "    ].copy()\n",
    "\n",
    "    # Merge Data\n",
    "    europe_map = europe_map.merge(\n",
    "        counts_df,\n",
    "        left_on=\"ISO_A2\",\n",
    "        right_on=cc_col,\n",
    "        how=\"left\"\n",
    "    )\n",
    "    europe_map[\"n_rows\"] = europe_map[\"n_rows\"].fillna(0)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    \n",
    "    europe_map.plot(\n",
    "        column=\"n_rows\",\n",
    "        cmap=\"Blues\",       \n",
    "        linewidth=0.5,\n",
    "        ax=ax,\n",
    "        edgecolor=\"0.6\",\n",
    "        legend=True,\n",
    "        legend_kwds={'label': \"Count\", 'shrink': 0.6},\n",
    "        missing_kwds={'color': '#f0f0f0'}\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: set view window BEFORE labeling/adjusting\n",
    "    ax.set_xlim(-32, 50)\n",
    "    ax.set_ylim(27, 72)\n",
    "\n",
    "    # LABELING LOOP\n",
    "    texts = []\n",
    "    for idx, row in europe_map.iterrows():\n",
    "        iso = row['ISO_A2']\n",
    "        count_val = row['n_rows']\n",
    "        \n",
    "        # Only label if we actually have data for this country\n",
    "        if count_val == 0: continue\n",
    "\n",
    "        # Standard Placement: Use the map's representative point\n",
    "        rep_point = row.geometry.representative_point()\n",
    "        x, y = rep_point.x, rep_point.y\n",
    "\n",
    "        # Draw Label (Only if inside zoom view)\n",
    "        if -32 < x < 50 and 27 < y < 72:\n",
    "            texts.append(ax.text(\n",
    "                x, y, iso,\n",
    "                fontsize=9,\n",
    "                ha='center', va='center',\n",
    "                color=\"white\",\n",
    "                fontweight='bold',\n",
    "                path_effects=[pe.withStroke(linewidth=2, foreground=\"black\")]\n",
    "            ))\n",
    "\n",
    "    # Keep labels on/near countries: small nudges, no arrows\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        ax=ax,\n",
    "        only_move={'text': 'xy'},\n",
    "        max_move=(10, 10),          # small move in points\n",
    "        force_text=(0.2, 0.2),\n",
    "        expand_text=(1.05, 1.1),\n",
    "        expand_points=(1.05, 1.1),\n",
    "        ensure_inside_axes=True,\n",
    "        lim=200\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_europe_choropleth(\"Airbnb Listings Density (Europe)\", pdf_airbnb_cc)\n",
    "plot_europe_choropleth(\"Travel Cities Coverage (Europe)\", pdf_cities_cc)\n",
    "plot_europe_choropleth(\"OSM POI Density (Europe)\", pdf_osm_cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4b54a8-ca3e-4b2b-87a0-61abeaac26a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "\n",
    "# # 1. Prepare Data\n",
    "# # Ensure your cities data is a GeoDataFrame\n",
    "# gdf_cities = gpd.GeoDataFrame(\n",
    "#     pdf_cities_coords, \n",
    "#     geometry=gpd.points_from_xy(pdf_cities_coords.longitude, pdf_cities_coords.latitude),\n",
    "#     crs=\"EPSG:4326\"\n",
    "# )\n",
    "\n",
    "# # 2. Perform the Spatial Join\n",
    "# # This attaches polygon info to the points. \n",
    "# # Points OUTSIDE the map will have 'index_right' as NaN.\n",
    "# joined = gpd.sjoin(gdf_cities, europe_map, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# # 3. Filter for the \"Floaters\"\n",
    "# outliers = joined[joined[\"index_right\"].isna()]\n",
    "\n",
    "# # 4. Show who they are\n",
    "# print(f\"Found {len(outliers)} points outside the map polygons.\")\n",
    "# display(outliers[[\"addr_cc\", \"latitude\", \"longitude\"]].head(10)) \n",
    "# # Note: If you have a 'city_name' column, add it to the display list above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e2e7a4-573d-4937-8e8b-c7632686857c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. SETUP: CONTINENT MAPPING & GEOMETRY\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Load World Map (Low res is fine for continents)\n",
    "world = gpd.read_file(\"https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip\")\n",
    "\n",
    "# Dissolve countries into Continents\n",
    "world_cont = world[[\"CONTINENT\", \"geometry\"]].dissolve(by=\"CONTINENT\").reset_index()\n",
    "world_cont = world_cont[world_cont[\"CONTINENT\"] != \"Seven seas (open ocean)\"].copy()\n",
    "\n",
    "# Canonical Mapping (Same as your code)\n",
    "CONTINENT_MAP = {\n",
    "    \"africa\": \"Africa\",\n",
    "    \"antarctica\": \"Antarctica\",\n",
    "    \"asia\": \"Asia\",\n",
    "    \"europe\": \"Europe\",\n",
    "    \"north_america\": \"North America\",\n",
    "    \"central_america\": \"North America\",\n",
    "    \"south_america\": \"South America\",\n",
    "    \"oceania\": \"Oceania\",\n",
    "    \"australia\": \"Oceania\",\n",
    "    \"australia_oceania\": \"Oceania\",\n",
    "    \"australia__oceania\": \"Oceania\",\n",
    "}\n",
    "\n",
    "def _norm_raw(x):\n",
    "    if x is None: return None\n",
    "    return str(x).lower().strip().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "def to_canonical_continent(x):\n",
    "    k = _norm_raw(x)\n",
    "    return CONTINENT_MAP.get(k, k)\n",
    "\n",
    "# Normalize geometry map side\n",
    "world_cont[\"continent_norm\"] = world_cont[\"CONTINENT\"].apply(_norm_raw).apply(to_canonical_continent)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. PREPARE DATA LAYERS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# LAYER 1: Airbnb Counts (Global)\n",
    "# We use your 'airbnb_counts' dataframe computed earlier\n",
    "pdf_ab_global = airbnb_counts.copy()\n",
    "pdf_ab_global[\"continent_norm\"] = pdf_ab_global[\"continent\"].apply(to_canonical_continent)\n",
    "# Sum duplicates (e.g. North America + Central America)\n",
    "pdf_ab_global = pdf_ab_global.groupby(\"continent_norm\")[\"n_rows\"].sum().reset_index()\n",
    "pdf_ab_global.columns = [\"continent_norm\", \"listings_count\"]\n",
    "\n",
    "# LAYER 2: OSM Counts (Global)\n",
    "# We use your 'osm_counts' dataframe computed earlier\n",
    "pdf_osm_global = osm_counts.copy()\n",
    "pdf_osm_global[\"continent_norm\"] = pdf_osm_global[\"continent\"].apply(to_canonical_continent)\n",
    "pdf_osm_global = pdf_osm_global.groupby(\"continent_norm\")[\"n_rows\"].sum().reset_index()\n",
    "pdf_osm_global.columns = [\"continent_norm\", \"osm_count\"]\n",
    "\n",
    "# LAYER 3: City Dots (Global)\n",
    "# We take a sample to keep plotting fast\n",
    "pdf_cities_global = cities_df.select(\"longitude\", \"latitude\").sample(fraction=0.5, seed=42).toPandas()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. MERGING DATA\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Merge Airbnb & OSM into the Geometry\n",
    "world_cont = world_cont.merge(pdf_ab_global, on=\"continent_norm\", how=\"left\")\n",
    "world_cont = world_cont.merge(pdf_osm_global, on=\"continent_norm\", how=\"left\")\n",
    "world_cont.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate Centroids for Bubbles (using temporary equal-area projection)\n",
    "world_cont[\"centroid\"] = world_cont.to_crs('+proj=cea').centroid.to_crs(world_cont.crs)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. PLOTTING\n",
    "# ---------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "\n",
    "# CHOROPLETH (Airbnb Density)\n",
    "world_cont.plot(\n",
    "    column=\"listings_count\",\n",
    "    ax=ax,\n",
    "    cmap=\"Blues\",\n",
    "    edgecolor=\"#999999\",\n",
    "    linewidth=0.5,\n",
    "    legend=True,\n",
    "    legend_kwds={'label': \"Total Listings\", 'shrink': 0.5},\n",
    "    missing_kwds={'color': '#f0f0f0'}\n",
    ")\n",
    "\n",
    "# BUBBLES (OSM Density)\n",
    "scale_factor = 4000 / world_cont[\"osm_count\"].max() \n",
    "ax.scatter(\n",
    "    world_cont[\"centroid\"].x, \n",
    "    world_cont[\"centroid\"].y, \n",
    "    s=world_cont[\"osm_count\"] * scale_factor, \n",
    "    color=\"#76c893\", \n",
    "    alpha=0.6, \n",
    "    edgecolor=\"#2d6a4f\", \n",
    "    linewidth=2,\n",
    "    zorder=2\n",
    ")\n",
    "\n",
    "# DOTS (Cities)\n",
    "# ax.scatter(\n",
    "#     pdf_cities_global[\"longitude\"], \n",
    "#     pdf_cities_global[\"latitude\"], \n",
    "#     color=\"#fc0f16\",  # instead of FF5A5F\n",
    "#     s=12, \n",
    "#     alpha=0.7, \n",
    "#     zorder=1\n",
    "# )\n",
    "ax.scatter(\n",
    "    pdf_cities_global[\"longitude\"], \n",
    "    pdf_cities_global[\"latitude\"], \n",
    "    color=\"#ff7034\", \n",
    "    s=60,               # Size of the pin\n",
    "    marker='v',         # 'v' points down\n",
    "    edgecolor=\"white\",  # Adds a white border so it stands out on the map\n",
    "    linewidth=0.5,\n",
    "    alpha=1.0,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "# LABELS\n",
    "# Use representative point for labeling continent names\n",
    "reps = world_cont.geometry.representative_point()\n",
    "for (name, x, y, osm_c) in zip(world_cont[\"CONTINENT\"], reps.x, reps.y, world_cont[\"osm_count\"]):\n",
    "    # Only label if we have data or it's a major landmass\n",
    "    if osm_c > 0:\n",
    "        ax.text(\n",
    "            x, y, \n",
    "            name.replace(\" (open ocean)\", \"\"), # Clean name\n",
    "            fontsize=10,\n",
    "            ha=\"center\", va=\"center\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", pad=1.5),\n",
    "            zorder=3\n",
    "        )\n",
    "\n",
    "# STYLING\n",
    "ax.set_title(\"Global Data Coverage\", fontsize=20, fontweight='bold')\n",
    "ax.axis(\"off\")\n",
    "ax.set_ylim(-60, 85) # Trim Antarctica slightly\n",
    "\n",
    "# Custom Legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='s', color='w', markerfacecolor='#2171b5', markersize=15, label='High Airbnb Supply'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#76c893', markersize=15, alpha=0.6, label='High OSM POI Count'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF5A5F', markersize=5, label='City Metadata Available')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower left', fontsize=12, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"global_data_coverage.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31590fc9-56a3-4673-9767-24c72082acf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Airbnb Counts (Choropleth Data)\n",
    "pdf_ab_counts = count_by_country(df_ab_eur).rename(columns={\"n_rows\": \"listings_count\"})\n",
    "\n",
    "# OSM Counts (Bubble Size Data)\n",
    "pdf_osm_counts = count_by_country(df_osm_eur).rename(columns={\"n_rows\": \"osm_count\"})\n",
    "\n",
    "# City Coordinates (Red Dots Data)\n",
    "pdf_cities_coords = cities_df.filter(F.col(\"addr_cc\").isin(europe_cc)) \\\n",
    "    .select(\"addr_cc\", \"longitude\", \"latitude\").toPandas()\n",
    "\n",
    "# LOAD & FILTER MAP\n",
    "# Use 50m resolution (better for Slovenia coastline, Malta, and islands)\n",
    "world = gpd.read_file(\"https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_countries.zip\")\n",
    "\n",
    "# Filter: Keep \"Europe\" OR the specific countries in our constant list\n",
    "europe_map = world[\n",
    "    (world[\"CONTINENT\"] == \"Europe\") | \n",
    "    (world[\"ISO_A2\"].isin(EXTRA_COUNTRIES))\n",
    "].copy()\n",
    "\n",
    "# MERGE AGGREGATED STATS\n",
    "# Merge Airbnb\n",
    "europe_map = europe_map.merge(pdf_ab_counts, left_on=\"ISO_A2\", right_on=\"addr_cc\", how=\"left\")\n",
    "# Merge OSM\n",
    "europe_map = europe_map.merge(pdf_osm_counts, left_on=\"ISO_A2\", right_on=\"addr_cc\", how=\"left\")\n",
    "\n",
    "# Fill NaNs\n",
    "europe_map[\"listings_count\"] = europe_map[\"listings_count\"].fillna(0)\n",
    "europe_map[\"osm_count\"] = europe_map[\"osm_count\"].fillna(0)\n",
    "\n",
    "# Calculate Centroids for the OSM Bubbles\n",
    "europe_map[\"centroid\"] = europe_map.geometry.centroid\n",
    "\n",
    "# PLOT\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# LAYER 1: BASE MAP (Airbnb Choropleth)\n",
    "europe_map.plot(\n",
    "    column=\"listings_count\",\n",
    "    ax=ax,\n",
    "    cmap=\"Blues\",\n",
    "    edgecolor=\"#d0d0d0\",\n",
    "    linewidth=0.5,\n",
    "    legend=True,\n",
    "    missing_kwds={'color': '#f9f9f9'}\n",
    ")\n",
    "\n",
    "# LAYER 2: OSM DENSITY (Green Bubbles)\n",
    "scale_factor = 2000 / europe_map[\"osm_count\"].max() \n",
    "ax.scatter(\n",
    "    europe_map[\"centroid\"].x, \n",
    "    europe_map[\"centroid\"].y, \n",
    "    s=europe_map[\"osm_count\"] * scale_factor, \n",
    "    color=\"#76c893\", \n",
    "    alpha=0.6,\n",
    "    edgecolor=\"#2d6a4f\",\n",
    "    linewidth=1,\n",
    "    zorder=2\n",
    ")\n",
    "\n",
    "# LAYER 3: TRAVEL CITIES (Red Dots)\n",
    "# ax.scatter(\n",
    "#     pdf_cities_coords[\"longitude\"], \n",
    "#     pdf_cities_coords[\"latitude\"], \n",
    "#     color=\"#fc0f16\", \n",
    "#     s=12, \n",
    "#     alpha=0.8,\n",
    "#     zorder=3\n",
    "# )\n",
    "\n",
    "ax.scatter(\n",
    "    pdf_cities_coords[\"longitude\"], \n",
    "    pdf_cities_coords[\"latitude\"], \n",
    "    color=\"#ff7034\", \n",
    "    s=60,               # Size of the pin\n",
    "    marker='v',         # 'v' points down\n",
    "    edgecolor=\"white\",  # Adds a white border so it stands out on the map\n",
    "    linewidth=0.5,\n",
    "    alpha=1.0,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "# FORMATTING\n",
    "ax.set_title(\"Europe Data Coverage\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Expanded limits to include Azores (left) and Canary Islands (bottom)\n",
    "ax.set_xlim(-32, 50)\n",
    "ax.set_ylim(27, 72)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Custom Legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#4292c6', markersize=15, label='High Airbnb Supply'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#76c893', markersize=15, alpha=0.6, label='High OSM/Vibe Density'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF5A5F', markersize=8, label='Rich City Metadata')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=11, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"europe_data_coverage.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6c484bf-9c8e-423a-8251-46031e4d9159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
