{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d8b5801-0542-491a-95e5-23930933de11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSHModel\n",
    "from retrieve_rank import retrieve, order\n",
    "from config import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e7d085d-d555-4a9b-a031-9b42d8e90ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_emb = (\n",
    "    spark.read.parquet(EMBEDDED_PATH)\n",
    "    .select(\"property_id\", \"addr_cc\", \"features_norm\")\n",
    "    .dropDuplicates([\"property_id\"])\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK)\n",
    ")\n",
    "\n",
    "df_all = (\n",
    "    spark.read.parquet(FULL_PATH)\n",
    "    .dropDuplicates([\"property_id\"])\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK)\n",
    ")\n",
    "\n",
    "lsh_model = BucketedRandomProjectionLSHModel.load(LSH_MODEL_PATH)\n",
    "\n",
    "MCQS_df = spark.read.parquet(MCQS_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f88cabd2-2635-4ef2-8430-d3e83f7476ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def infer_env_cols_from_columns(cols: list[str]) -> list[str]:\n",
    "    env_norm = [c for c in cols if c.startswith(\"env_\") and c.endswith(\"_norm\")]\n",
    "    if env_norm:\n",
    "        return sorted(env_norm)\n",
    "    env_raw = [c for c in cols if c.startswith(\"env_\") and (not c.endswith(\"_max\")) and (not c.endswith(\"_norm\"))]\n",
    "    return sorted(env_raw)\n",
    "\n",
    "ENV_COLS = infer_env_cols_from_columns(df_all.columns)\n",
    "\n",
    "save_cols = [\"property_id\", \"addr_cc\", \"lat\", \"long\", \"listing_title\", \"room_type_text\", \"addr_name\", \"price_per_night\", \"ratings\", 'l2_dist', 'cosine_similarity', \"final_url\"]\n",
    "\n",
    "temp_pref=22\n",
    "travel_month=6\n",
    "budget_pref=\"Mid-range\"\n",
    "\n",
    "configs={\n",
    "        \"airbnb\":{\n",
    "            \"price_w\":90,\n",
    "            \"property_w\":90,\n",
    "            \"host_w\":90,\n",
    "            \"env_weights\":{col:10 for col in ENV_COLS},\n",
    "            \"temp_pref\":temp_pref,\n",
    "            \"temp_w\":10,\n",
    "            \"travel_month\":travel_month,\n",
    "            \"budget_pref\":budget_pref,\n",
    "            \"budget_w\":10,\n",
    "            \"normalize_all_weights\":True,\n",
    "            \"score_col\":\"final_score\"\n",
    "        },\n",
    "        \"cities\":{\n",
    "            \"price_w\":10,\n",
    "            \"property_w\":10,\n",
    "            \"host_w\":10,\n",
    "            \"env_weights\":{col:10 for col in ENV_COLS},\n",
    "            \"temp_pref\":temp_pref,\n",
    "            \"temp_w\":90,\n",
    "            \"travel_month\":travel_month,\n",
    "            \"budget_pref\":budget_pref,\n",
    "            \"budget_w\":90,\n",
    "            \"normalize_all_weights\":True,\n",
    "            \"score_col\":\"final_score\"\n",
    "        },\n",
    "        \"neigh\":{\n",
    "            \"price_w\":10,\n",
    "            \"property_w\":10,\n",
    "            \"host_w\":10,\n",
    "            \"env_weights\":{col:90 for col in ENV_COLS},\n",
    "            \"temp_pref\":temp_pref,\n",
    "            \"temp_w\":10,\n",
    "            \"travel_month\":travel_month,\n",
    "            \"budget_pref\":budget_pref,\n",
    "            \"budget_w\":10,\n",
    "            \"normalize_all_weights\":True,\n",
    "            \"score_col\":\"final_score\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa1e51f-0587-4b1c-aa8a-2b24b5ff21c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_for_id(id, dest_cc):\n",
    "    import os\n",
    "    cand_df = MCQS_df.filter((MCQS_df.target_id == id) & (MCQS_df.cand_cc == dest_cc)).orderBy(F.col(\"l2_dist\").asc())\n",
    "    # save top 5 to csv using pandas\n",
    "    pdf = cand_df.select(save_cols).limit(5).toPandas()\n",
    "    pdf.to_csv(f\"{id}_{dest_cc}.csv\", index=False)\n",
    "    return cand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e50b00-69e5-4da1-bb21-cf8196f4167c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "def save_reordered(cand_df, id, dest_cc):\n",
    "    for cfg_name, cfg in configs.items():\n",
    "        print(cfg_name)\n",
    "        cand_df_reordered=order(\n",
    "            df=cand_df,\n",
    "            k=5,\n",
    "            price_w=cfg[\"price_w\"],\n",
    "            property_w=cfg[\"property_w\"],\n",
    "            host_w=cfg[\"host_w\"],\n",
    "            env_weights=cfg[\"env_weights\"],\n",
    "            temp_pref=cfg[\"temp_pref\"],\n",
    "            temp_w=cfg[\"temp_w\"],\n",
    "            travel_month=cfg[\"travel_month\"],\n",
    "            budget_pref=cfg[\"budget_pref\"],\n",
    "            budget_w=cfg[\"budget_w\"],\n",
    "            normalize_all_weights=cfg[\"normalize_all_weights\"],\n",
    "            score_col=cfg[\"score_col\"]\n",
    "        )\n",
    "        pdf = cand_df_reordered.select(['final_score']+save_cols).toPandas()\n",
    "        pdf.to_csv(f\"{cfg_name}_{id}_{dest_cc}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615c6740-289c-4f9a-b505-0577bbd51846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "queries = {47067457:\"FR\", 4214278:\"ES\", 898514755547253537:\"AX\"}\n",
    "for query_id, dest_cc in queries.items():\n",
    "    cand_df = retrieve_for_id(query_id, dest_cc)\n",
    "    save_reordered(cand_df, query_id, dest_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6866252e-f664-4f46-8df7-cda36ef3cc52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_data = spark.read.parquet(MCQS_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a1434d-d91d-47cf-bfb3-e12ce5a1a804",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(query_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21634f1a-4892-4784-a0fa-9c95c46bff94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filter to only properties that are in queries\n",
    "df_to_save = (\n",
    "    query_data.filter(\n",
    "        query_data.property_id.isin(list(queries.keys()))\n",
    "    ).select([\n",
    "        \"property_id\",\n",
    "        \"addr_cc\",\n",
    "        \"lat\",\n",
    "        \"long\",\n",
    "        \"listing_title\",\n",
    "        \"room_type_text\",\n",
    "        \"addr_name\",\n",
    "        \"price_per_night\",\n",
    "        \"ratings\",\n",
    "        \"final_url\"\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02b94c4-459d-40e8-b2b3-6b770c26af0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f4c4dd-8fae-4600-9514-75dd15bf8b30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# convert to pandas df and save as csv\n",
    "df_to_save.toPandas().to_csv(\"query_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "qualitative_eval_",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
